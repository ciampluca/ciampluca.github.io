<!DOCTYPE html>
<html lang="en" ng-app="AdvApp">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Unsupervised Domain Adaptation for Traffic Density Estimation and Counting</title>
    
    <!-- Latest compiled and minified JavaScript -->
    <script src="https://code.jquery.com/jquery-1.12.4.min.js" integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin="anonymous"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/angularjs/1.6.4/angular.min.js" crossorigin="anonymous"></script>
    <script src="ng-infinite-scroll.min.js" type="application/javascript"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
    
    <!--
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-97320150-1', 'auto');
    ga('send', 'pageview'); 

    
    </script> -->
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    
    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <!-- Optional theme -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">    
    <!-- Fonts! -->
    <link href="http://fonts.googleapis.com/css?family=Roboto:400,300" rel="stylesheet" type="text/css">
    
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            font-weight: 200;
            font-size: 16px;
            text-align: justify;
        }
        h1 { text-align: center; margin-top: 20px; }
	h2 { margin-bottom: 20px; }
        .container > * { margin-bottom: 50px }
        #table-container { margin-top: 50px; height: 600px; overflow: auto; }
        #table-container tbody td { vertical-align: middle; }
        #table-container tbody td.class-text { width: 27%; text-align: left; }
        .score { font-weight: bold; text-align: center; }
        .thumb div {    
            width: 120px;
            height: 120px;
            display: inline-block;
            background-position: center center;
            background-size: cover;
        }

        .center {
            display: block;
            margin-left: auto;
            margin-right: auto;
            width: 50%;
            border: 2px;
            border-color: #bbbbbb;
            border-radius: 4px;
            box-shadow: 0 0 2px 2px rgba(0, 140, 186, 0.7);
        }

        .samples-footer {
            width: 100%;
            padding: 10px;
            box-shadow: 0 2px 4px 0 rgba(0,0,0,0.16),0 2px 10px 0 rgba(0,0,0,0.12) !important;
            background-color: #f1f1f1fa;
            display: inline-block;
        }
        .samples-footer a{
            float: right;
        }
	li {margin-bottom: 10px}

        .disabledLink {
            pointer-events:none;
        }

	@media (max-width: 400px) {
    		.center {
        		width: 100%;
    		}
	}

	ul {list-style-type: circle; }

	pre {
		background-color: rgb(246, 248, 250);
		border-bottom-left-radius: 3px;
		border-bottom-right-radius: 3px;
		border-top-left-radius: 3px;
		border-top-right-radius: 3px;
		box-sizing: border-box;
		color: rgb(36, 41, 46);
		font-family: SFMono-Regular, Consolas, Liberation Mono, Menlo, monospace;
		font-size: 13.6px;
		line-height: 19.7167px;
		margin-bottom: 0px;
		margin-top: 20px;
		overflow: auto;
		overflow-wrap: normal;
		overflow-x: auto;
		overflow-y: auto;
		padding-left: 35px;
		padding-bottom: 35px;
		padding-right: 35px;
	}

	code {
		background-attachment: scroll;
		background-clip: border-box;
		background-color: rgba(0, 0, 0, 0);
		background-image: none;
		background-origin: padding-box;
		background-position: 0% 0%;
		background-position-x: 0%;
		background-position-y: 0%;
		background-repeat: repeat;
		background-size: auto;
		border-bottom-color: rgb(36, 41, 46);
		border-bottom-left-radius: 3px;
		border-bottom-right-radius: 3px;
		border-bottom-style: none;
		border-bottom-width: 0px;
		border-image-outset: 0;
		border-image-repeat: stretch;
		border-image-slice: 100%;
		border-image-source: none;
		border-image-width: 1;
		border-left-color: rgb(36, 41, 46);
		border-left-style: none;
		border-left-width: 0px;
		border-right-color: rgb(36, 41, 46);
		border-right-style: none;
		border-right-width: 0px;
		border-top-color: rgb(36, 41, 46);
		border-top-left-radius: 3px;
		border-top-right-radius: 3px;
		border-top-style: none;
		border-top-width: 0px;
		box-sizing: border-box;
		color: rgb(36, 41, 46);
		display: inline;
		font-family: SFMono-Regular, Consolas, Liberation Mono, Menlo, monospace;
		font-size: 13.6px;
		line-height: 19.7167px;
		margin-bottom: 0px;
		margin-left: 0px;
		margin-right: 0px;
		margin-top: 0px;
		overflow: visible;
		overflow-wrap: normal;
		overflow-x: visible;
		overflow-y: visible;
		padding-bottom: 0px;
		padding-left: 0px;
		padding-right: 0px;
		padding-top: 0px;
		white-space: pre;
		word-break: normal;
	}
	</style>
</head>
<body>
    <div class="container">
        <h1>
            Unsupervised Domain Adaptation for Traffic Density Estimation and Counting<br>
            <small>
                <a href="https://scholar.google.it/citations?user=dCjyf-8AAAAJ&hl=it">Luca Ciampi</a>,
		        <a href="https://scholar.google.com/citations?user=f17rSrgAAAAJ&hl=pt-PT">Carlos Santiago</a>,
                <a href="https://scholar.google.com/citations?user=Xi33QRIAAAAJ&hl=en">Joao Paulo Costeira</a>,
                <a href="https://scholar.google.it/citations?user=sbFBI4IAAAAJ&hl=en">Claudio Gennaro</a>,
		        <a href="https://scholar.google.it/citations?user=dXcskhIAAAAJ&hl=en">Giuseppe Amato</a>
            </small>
        </h1>
        
        
        <div class="abstract">
            <h2>Abstract</h2>
            <p> Convolutional Neural Networks have produced state-of-the-art results for a multitude of tasks. However, the crux of these supervised methods is represented by the need for a massive amount of labeled data, and generalizing well to diverse testing scenarios remains a significant challenge. In many real-world applications, there is indeed a large <i>domain shift</i> between the distributions of the train (<i>source</i>) and test (<i>target</i>) domains, which implies a pronounced drop in performance at inference-time. Hence, algorithms that can automatically infer some knowledge from the <i>unlabeled</i> target dataset getting closer the two domains and relying only on the labeled source supervised learning are of great interest. This class of techniques is known as <i>Unsupervised Domain Adaptation</i> (UDA), and it is particularly useful for the tasks in which acquiring new labeled data is very expensive, like instance and semantic segmentation. In this work, we propose an end-to-end CNN-based UDA algorithm for traffic density estimation and counting, based on adversarial learning in the <i>output space</i>. The density estimation is one of those tasks requiring per-pixel annotated labels and, therefore, needs a lot of human effort. We conduct experiments considering different domain shift, and we make publicly available two new datasets for the vehicle counting task. One of them, named <i>GTA - Grand Traffic Auto</i>, is a <i>synthetic</i> collection of images taken from a video game and <i>automatically</i> annotated with precise per-pixel labels. Experiments show a significant improvement compared to the performance of the model without domain adaptation.
            </p>
        </div>
 

	<div class="container">
	  <div class="row">
	    <div class="col-6 col-md-6"><img class="img-thumbnail" src="laziseDay.png"></div>
	    <div class="col-6 col-md-6"><img class="img-thumbnail" src="grand_traffic_auto-compressed.png"></div>
	    <div class="col-6 col-md-6"><img class="img-thumbnail" src="grand_traffic_auto-compressed.png"></div>
	    <div class="w-100"></div>
	    <div class="col-6 col-md-6"><img class="img-thumbnail" src="lazise_night-compressed.png"></div>
	    <div class="col-6 col-md-6"><img class="img-thumbnail" src="webcamtTest.png"></div>
	    <div class="col-6 col-md-6"><img class="img-thumbnail" src="webcamtTest.png"></div>
	  </div> 
	</div>


        <div class="paper">
            <h2>Papers</h2>
		<ul>
			<li><b>Unsupervised Domain Adaptation for Traffic Density Estimation and Counting</b> (<a href="file.pdf"> Download</a>, 3.3MB). The paper has been submitted at <a href="https://www.micc.unifi.it/icpr2020/">ICPR 2020</a>.
			</li>
			<li><b>Unsupervised Vehicle Counting via Multiple CameraDomain Adaptation</b> <a href="paper"> (Download</a>, 7.7MB). The paper has been accepted at <a href="http://nehuai2020.aass.oru.se/">ECAI-2020 Workshop on "New Foundations for
Human-Centered AI"</a>
			</li>
		</ul>
        </div>

        <div class="dataset">
            <p>
            Working in progress...
            </p>
        </div>
        <div class="cite">
	    <h2>Cite our work</h2>
		If you find this work or code useful for your research, please cite the following:
		<p>
		Work in progress....
		</p>
		 <!-- 
		<pre><code>
@inproceedings{amato2019learning,
  title={Learning pedestrian detection from virtual worlds},
  author={Amato, Giuseppe and Ciampi, Luca and Falchi, Fabrizio and Gennaro, Claudio and Messina, Nicola},
  booktitle={International Conference on Image Analysis and Processing},
  pages={302--312},
  year={2019},
  organization={Springer}
}
@misc{ciampi2020virtual,
    title={Virtual to Real adaptation of Pedestrian Detectors for Smart Cities},
    author={Luca Ciampi and Nicola Messina and Fabrizio Falchi and Claudio Gennaro and Giuseppe Amato},
    year={2020},
    eprint={2001.03032},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
</code></pre>
-->
	</div>
        <div class="acks">
            <p>
This work was partially supported by LARSyS-FCT Plurianual funding 2020-2023 and by H2020 project AI4EU under GA 825619.</p>
        </div>
    </div>
</body>
</html>


